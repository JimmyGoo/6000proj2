{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from numpy.random import normal\n",
        "from typing import Optional, Union, Callable\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.experimental.output_all_intermediates(True)\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Layer, TimeDistributed, Lambda, Activation\n",
        "from tensorflow.keras.initializers import Ones, Zeros\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.initializers import glorot_normal\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()"
      ],
      "metadata": {
        "id": "NbItvdNJdVLG"
      },
      "id": "NbItvdNJdVLG",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# refer to # # https://www.kaggle.com/shujian/transformer-with-lstm\n",
        "# define the multi-head transformer structure by hand\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self._eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self._gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self._beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self._gamma * (x - mean) / (std + self._eps) + self._beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "class ScaledDotProductAttention():\n",
        "    def __init__(self, d_model, attn_dropout=0.1):\n",
        "        self._temper = np.sqrt(d_model)\n",
        "        self._dropout = Dropout(attn_dropout)\n",
        "    def __call__(self, q, k, v, mask):\n",
        "        attn = Lambda(lambda x:K.batch_dot(x[0],x[1],axes=[2,2])/self._temper)([q, k])\n",
        "        if mask is not None:\n",
        "            mmask = Lambda(lambda x:(-1e+10)*(1-x))(mask)\n",
        "            attn = Add()([attn, mmask])\n",
        "        attn = Activation('softmax')(attn)\n",
        "        attn = self._dropout(attn)\n",
        "        output = Lambda(lambda x:K.batch_dot(x[0], x[1]))([attn, v])\n",
        "        return output, attn\n",
        "\n",
        "\n",
        "class MultiHeadAttention():\n",
        "    # mode 0 - big martixes, faster; mode 1 - more clear implementation\n",
        "    def __init__(self, num_head, dim_model, dim_key, dim_value, dropout, mode=0, use_norm=True):\n",
        "        self._head_mode = mode\n",
        "        self._num_head = num_head\n",
        "        self._dim_key = dim_key\n",
        "        self._dim_value = dim_value\n",
        "        self._dropout = dropout\n",
        "        if self._head_mode == 0:\n",
        "            self.qs_layer = Dense(num_head*dim_key, use_bias=False)\n",
        "            self.ks_layer = Dense(num_head*dim_key, use_bias=False)\n",
        "            self.vs_layer = Dense(num_head*dim_value, use_bias=False)\n",
        "        elif self._head_mode == 1:\n",
        "            self.qs_layers = []\n",
        "            self.ks_layers = []\n",
        "            self.vs_layers = []\n",
        "            for _ in range(num_head):\n",
        "                self.qs_layers.append(TimeDistributed(Dense(dim_key, use_bias=False)))\n",
        "                self.ks_layers.append(TimeDistributed(Dense(dim_key, use_bias=False)))\n",
        "                self.vs_layers.append(TimeDistributed(Dense(dim_value, use_bias=False)))\n",
        "        self.attention = ScaledDotProductAttention(dim_model)\n",
        "        self.layer_norm = LayerNormalization() if use_norm else None\n",
        "        self.w_o = TimeDistributed(Dense(dim_model))\n",
        "\n",
        "\n",
        "    def __call__(self, q, k, v, mask=None):\n",
        "        from keras.layers import Concatenate\n",
        "        if self._head_mode == 0:\n",
        "            qs = self.qs_layer(q) \n",
        "            ks = self.ks_layer(k)\n",
        "            vs = self.vs_layer(v)\n",
        "\n",
        "            def reshape1(x):\n",
        "                shape = tf.shape(x) \n",
        "                x = tf.reshape(x, [shape[0], shape[1], self._num_head, self._dim_key])\n",
        "                x = tf.transpose(x, [2, 0, 1, 3])  \n",
        "                x = tf.reshape(x, [-1, shape[1], self._dim_key])\n",
        "                return x\n",
        "            qs = Lambda(reshape1)(qs)\n",
        "            ks = Lambda(reshape1)(ks)\n",
        "            vs = Lambda(reshape1)(vs)\n",
        "\n",
        "            if mask is not None:\n",
        "                mask = Lambda(lambda x:K.repeat_elements(x, self._num_head, 0))(mask)\n",
        "            head, attn = self.attention(qs, ks, vs, mask=mask)  \n",
        "                \n",
        "            def reshape2(x):\n",
        "                shape = tf.shape(x)\n",
        "                x = tf.reshape(x, [self._num_head, -1, shape[1], shape[2]]) \n",
        "                x = tf.transpose(x, [1, 2, 0, 3])\n",
        "                x = tf.reshape(x, [-1, shape[1], self._num_head*self._dim_value])\n",
        "                return x\n",
        "            head = Lambda(reshape2)(head)\n",
        "        elif self._head_mode == 1:\n",
        "            heads = []; attns = []\n",
        "            for i in range(self._num_head):\n",
        "                qs = self.qs_layers[i](q)   \n",
        "                ks = self.ks_layers[i](k) \n",
        "                vs = self.vs_layers[i](v) \n",
        "                head, attn = self.attention(qs, ks, vs, mask)\n",
        "                heads.append(head); attns.append(attn)\n",
        "            head = Concatenate()(heads) if self._num_head > 1 else heads[0]\n",
        "            attn = Concatenate()(attns) if self._num_head > 1 else attns[0]\n",
        "\n",
        "        outputs = self.w_o(head)\n",
        "        outputs = Dropout(self._dropout)(outputs)\n",
        "        if not self.layer_norm: return outputs, attn\n",
        "        # outputs = Add()([outputs, q]) # sl: fix\n",
        "        return self.layer_norm(outputs), attn\n"
      ],
      "metadata": {
        "id": "X3xfvmgtdRff"
      },
      "id": "X3xfvmgtdRff",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import GlobalMaxPooling1D, Flatten, GlobalAveragePooling1D, Reshape, concatenate\n",
        "class Transformer:\n",
        "    def __init__(self, win_len, input_dim, hidden_dim=[128,64], attn_mode=0, head_mode=0):\n",
        "        self.name = 'Transformer'\n",
        "        self._win_len = win_len\n",
        "        self._input_dim = input_dim\n",
        "        self._hidden_dim = hidden_dim\n",
        "        # if attn_mode = 1, it will deploy the handmade multihead attention layer\n",
        "        # if attn_mode = 0, it will deploy the keras multihead attention layer\n",
        "        self._attn_mode = attn_mode\n",
        "        self._head_mode = head_mode\n",
        "    \n",
        "\n",
        "    # 需要 loss function\n",
        "    def _build_loss(self, sigma: tf.Tensor) -> Callable:\n",
        "\n",
        "        def gaussian_likelihood(y_true, y_pred):\n",
        "            return tf.reduce_mean(\n",
        "                tf.math.log(tf.math.sqrt(2 * math.pi))\n",
        "                + tf.math.log(sigma)\n",
        "                + tf.math.truediv(\n",
        "                    tf.math.square(y_true - y_pred), 2 * tf.math.square(sigma)\n",
        "                )\n",
        "            )\n",
        "            \n",
        "        return gaussian_likelihood\n",
        "\n",
        "    def build_and_compile(self) -> None:\n",
        "        inputs = Input(shape=(self._win_len, self._input_dim))\n",
        "        lstm_out1 = LSTM(self._hidden_dim[0], return_sequences=True)(inputs)\n",
        "        x = LSTM(self._hidden_dim[1], return_sequences=True)(lstm_out1) \n",
        "        if self._attn_mode == 1:\n",
        "          x, slf_attn = MultiHeadAttention(num_head=3, dim_model=300, \n",
        "                                           dim_key=self._hidden_dim[1], \n",
        "                                           dim_value=self._hidden_dim[1], \n",
        "                                           dropout=0.1, \n",
        "                                           mode=self._head_mode)(x, x, x)\n",
        "        elif self._attn_mode == 0:\n",
        "          x, slf_attn = layers.MultiHeadAttention(\n",
        "                num_heads=3,\n",
        "                key_dim=self._hidden_dim[1],\n",
        "                value_dim=self._hidden_dim[1],\n",
        "                dropout=0.1)(x, x, x,\n",
        "                return_attention_scores=True)\n",
        "        else:\n",
        "          print('Wrong attn_mode input. Attention layer will not be deployed.')\n",
        "        avg_pool = GlobalAveragePooling1D()(x)\n",
        "        max_pool = GlobalMaxPooling1D()(x)\n",
        "        conc = concatenate([avg_pool, max_pool])\n",
        "        dense = Dense(self._hidden_dim[1], activation=\"relu\")(conc)\n",
        "        dense_out = Dense(self._input_dim)(dense)      \n",
        "\n",
        "        model = Model(inputs=inputs, outputs=dense_out)\n",
        "\n",
        "        model.compile(\n",
        "            loss='mse',\n",
        "            metrics=['mse'],\n",
        "        )\n",
        "\n",
        "        self._model = model\n",
        "\n",
        "    def get_model(self) -> Model:\n",
        "        return self._model\n",
        "\n",
        "    def summary(self) -> None:\n",
        "        self._model.summary()\n",
        "\n",
        "    def fit(self, **kwargs) -> None:\n",
        "        self._model.fit(**kwargs)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        return self._model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "Aoi6gVQRdgHn"
      },
      "id": "Aoi6gVQRdgHn",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# to use the packages in google drive\n",
        "sys.path.append('/content/drive/My Drive/6000M_proj2/proj2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eojJlWOejZdp",
        "outputId": "0845da4d-8e8e-4253-e735-2ab0e1346263"
      },
      "id": "eojJlWOejZdp",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install loguru"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKHs1blXjoTY",
        "outputId": "2bd2af75-201f-4470-be24-f37e2e14aa45"
      },
      "id": "BKHs1blXjoTY",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.9/dist-packages (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout, LeakyReLU, LSTM, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from loguru import logger\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from scipy.stats import skew, kurtosis\n",
        "from os.path import join\n",
        "\n",
        "from config import *\n",
        "\n",
        "from src.universe import Universe\n",
        "from src.utils import time_series_generator\n",
        "from src.metrics import plot_mse"
      ],
      "metadata": {
        "id": "q9qMvQknjbXQ"
      },
      "id": "q9qMvQknjbXQ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception_date = '2022-03-31'\n",
        "ONE_YEAR_TRADE_DAYS = 252\n",
        "TWO_YEAR_TRADE_DAYS = ONE_YEAR_TRADE_DAYS * 2\n",
        "WIN_LEN = 30\n",
        "UNIVERSE_SIZE = 2500\n",
        "EPOCH = 20\n",
        "BATCH_SIZE = 16\n",
        "training_path = Path(join(data_path, 'train_set'))\n",
        "ret_train = pd.read_csv(join(training_path, '2022-03-31.csv'), index_col=0)\n",
        "X, y = time_series_generator(ret_train, WIN_LEN)\n",
        "train_index = ret_train.loc[:inception_date].iloc[-TWO_YEAR_TRADE_DAYS:].index\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y)\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry6RizLdjNfy",
        "outputId": "5c7c37e7-a6d0-4b2f-9e97-cdb74b06f8b9"
      },
      "id": "Ry6RizLdjNfy",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((378, 30, 2500), (126, 30, 2500), (378, 2500), (126, 2500))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_api_matrix = Transformer(30, 2500, [128, 64], attn_mode=0, head_mode=0)\n",
        "transformer_hand_matrix = Transformer(30, 2500, [128, 64], attn_mode=1, head_mode=0)\n",
        "transformer_hand_timedis = Transformer(30, 2500, [128, 64], attn_mode=1, head_mode=1)"
      ],
      "metadata": {
        "id": "5NspXTuAjNSR"
      },
      "id": "5NspXTuAjNSR",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_api_matrix.build_and_compile()\n",
        "transformer_hand_matrix.build_and_compile()\n",
        "transformer_hand_timedis.build_and_compile()"
      ],
      "metadata": {
        "id": "chaIYU5wj5vh"
      },
      "id": "chaIYU5wj5vh",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_api_matrix.fit(x=X_train, y=y_train,\n",
        "                    epochs=EPOCH,\n",
        "                    validation_data=(X_val, y_val),)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FMJapn_nB58",
        "outputId": "b2d42bdc-3a32-4e5f-c313-5fb693a1658f"
      },
      "id": "0FMJapn_nB58",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 378 samples, validate on 126 samples\n",
            "Epoch 1/20\n",
            "378/378 [==============================] - ETA: 0s - loss: 0.0026 - mse: 0.0026"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r378/378 [==============================] - 8s 21ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 2/20\n",
            "378/378 [==============================] - 6s 16ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 3/20\n",
            "378/378 [==============================] - 8s 20ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 4/20\n",
            "378/378 [==============================] - 6s 16ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 5/20\n",
            "378/378 [==============================] - 8s 21ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 6/20\n",
            "378/378 [==============================] - 6s 16ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 7/20\n",
            "378/378 [==============================] - 6s 16ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 8/20\n",
            "378/378 [==============================] - 3s 9ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 9/20\n",
            "378/378 [==============================] - 3s 8ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 10/20\n",
            "378/378 [==============================] - 3s 8ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 11/20\n",
            "378/378 [==============================] - 4s 11ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 12/20\n",
            "378/378 [==============================] - 4s 10ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 13/20\n",
            "378/378 [==============================] - 3s 8ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 14/20\n",
            "378/378 [==============================] - 3s 8ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 15/20\n",
            "378/378 [==============================] - 4s 11ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 16/20\n",
            "378/378 [==============================] - 4s 11ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 17/20\n",
            "378/378 [==============================] - 3s 8ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 18/20\n",
            "378/378 [==============================] - 3s 8ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 19/20\n",
            "378/378 [==============================] - 4s 10ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 20/20\n",
            "378/378 [==============================] - 4s 11ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_hand_matrix.fit(x=X_train, y=y_train,\n",
        "                    epochs=EPOCH,\n",
        "                    validation_data=(X_val, y_val),)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtofoGGZ2AmZ",
        "outputId": "56784e03-a807-41aa-85f1-8fa6dbb9b5d3"
      },
      "id": "DtofoGGZ2AmZ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 378 samples, validate on 126 samples\n",
            "Epoch 1/20\n",
            "378/378 [==============================] - 5s 12ms/sample - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 2/20\n",
            "378/378 [==============================] - 4s 10ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 3/20\n",
            "378/378 [==============================] - 4s 12ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 4/20\n",
            "378/378 [==============================] - 3s 9ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 5/20\n",
            "378/378 [==============================] - 3s 8ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 6/20\n",
            "378/378 [==============================] - 4s 11ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 7/20\n",
            "378/378 [==============================] - 4s 11ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 8/20\n",
            "378/378 [==============================] - 3s 9ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 9/20\n",
            "378/378 [==============================] - 3s 8ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0031 - val_mse: 0.0031\n",
            "Epoch 10/20\n",
            "378/378 [==============================] - 6s 15ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0045 - val_mse: 0.0045\n",
            "Epoch 11/20\n",
            "378/378 [==============================] - 5s 14ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 12/20\n",
            "378/378 [==============================] - 3s 9ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 13/20\n",
            "378/378 [==============================] - 4s 10ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0031 - val_mse: 0.0031\n",
            "Epoch 14/20\n",
            "378/378 [==============================] - 5s 12ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 15/20\n",
            "378/378 [==============================] - 3s 9ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 16/20\n",
            "378/378 [==============================] - 3s 9ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 17/20\n",
            "378/378 [==============================] - 4s 11ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 18/20\n",
            "378/378 [==============================] - 4s 12ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 19/20\n",
            "378/378 [==============================] - 3s 8ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 20/20\n",
            "378/378 [==============================] - 3s 8ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0028 - val_mse: 0.0028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_hand_timedis.fit(x=X_train, y=y_train,\n",
        "                    epochs=EPOCH,\n",
        "                    validation_data=(X_val, y_val),)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMvusKz22ElD",
        "outputId": "c0d987c2-3b77-4428-c933-964de65ce2ae"
      },
      "id": "gMvusKz22ElD",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 378 samples, validate on 126 samples\n",
            "Epoch 1/20\n",
            "378/378 [==============================] - 7s 17ms/sample - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 2/20\n",
            "378/378 [==============================] - 3s 9ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 3/20\n",
            "378/378 [==============================] - 3s 9ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 4/20\n",
            "378/378 [==============================] - 5s 13ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 5/20\n",
            "378/378 [==============================] - 4s 10ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 6/20\n",
            "378/378 [==============================] - 3s 9ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 7/20\n",
            "378/378 [==============================] - 3s 9ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 8/20\n",
            "378/378 [==============================] - 5s 14ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0033 - val_mse: 0.0033\n",
            "Epoch 9/20\n",
            "378/378 [==============================] - 5s 12ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 10/20\n",
            "378/378 [==============================] - 4s 12ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 11/20\n",
            "378/378 [==============================] - 6s 15ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 12/20\n",
            "378/378 [==============================] - 4s 10ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 13/20\n",
            "378/378 [==============================] - 3s 9ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 14/20\n",
            "378/378 [==============================] - 3s 9ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 15/20\n",
            "378/378 [==============================] - 5s 14ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 16/20\n",
            "378/378 [==============================] - 3s 9ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 17/20\n",
            "378/378 [==============================] - 3s 9ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0031 - val_mse: 0.0031\n",
            "Epoch 18/20\n",
            "378/378 [==============================] - 3s 9ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0031 - val_mse: 0.0031\n",
            "Epoch 19/20\n",
            "378/378 [==============================] - 5s 14ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0031 - val_mse: 0.0031\n",
            "Epoch 20/20\n",
            "378/378 [==============================] - 3s 9ms/sample - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0030 - val_mse: 0.0030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_path = Path(join(data_path, 'train_set'))\n",
        "liquid_ticker_ret = pd.read_csv(join(training_path, 'liquid_ticker_ret.csv'), index_col=0)\n",
        "ret_train = liquid_ticker_ret.loc[:inception_date].iloc[-TWO_YEAR_TRADE_DAYS-WIN_LEN:]\n",
        "train_index = ret_train.loc[:inception_date].iloc[-TWO_YEAR_TRADE_DAYS:].index\n",
        "train_flat = ret_train.values.flatten()\n",
        "train_flat = train_flat[train_flat != 0]\n",
        "m = train_flat.mean()\n",
        "s = train_flat.std()\n",
        "train_flat = train_flat.clip(m-2*s, m+2*s)\n",
        "sns.kdeplot(train_flat)\n",
        "## get ticker returns\n",
        "test_start_date = liquid_ticker_ret.loc[:inception_date].iloc[-WIN_LEN:].index[0]\n",
        "ret_test = liquid_ticker_ret.loc[test_start_date:].iloc[:ONE_YEAR_TRADE_DAYS + WIN_LEN+1]\n",
        "ret_test = ret_test.clip(m-2*s, m+2*s)\n",
        "X_test, y_test = time_series_generator(ret_test, WIN_LEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "iAUmzgx6-Zfk",
        "outputId": "e5c10567-9076-4c57-af73-a0a6b9c250e8"
      },
      "id": "iAUmzgx6-Zfk",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test_api_matrix = transformer_api_matrix.predict(X_test)\n",
        "y_pred_test_hand_matrix = transformer_hand_matrix.predict(X_test)\n",
        "y_pred_test_hand_timedis = transformer_hand_timedis.predict(X_test)\n"
      ],
      "metadata": {
        "id": "hxOB5r6n-fUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa75f711-fe4f-4b7c-8d90-370fadbff92b"
      },
      "id": "hxOB5r6n-fUN",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.metrics import plot_mse, generate_report\n",
        "generate_report(\n",
        "    [y_pred_test_api_matrix, y_pred_test_hand_matrix, y_pred_test_hand_timedis], y_test, \n",
        "    ['transformer_api', 'handmade_attention_matrix_form', 'handmade_attention_time_distributed_form']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "6wmfUx6m3GSR",
        "outputId": "63d2efc3-dcc8-496c-82c4-51490db2a9b8"
      },
      "id": "6wmfUx6m3GSR",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               mse      corr  deviation\n",
              "transformer_api                           0.002658  0.043304   1.065924\n",
              "handmade_attention_matrix_form            0.002770  0.000387   1.146424\n",
              "handmade_attention_time_distributed_form  0.003004  0.000743   1.213847"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68366cc2-507c-4aa7-a8f8-1e2b17471791\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mse</th>\n",
              "      <th>corr</th>\n",
              "      <th>deviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>transformer_api</th>\n",
              "      <td>0.002658</td>\n",
              "      <td>0.043304</td>\n",
              "      <td>1.065924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>handmade_attention_matrix_form</th>\n",
              "      <td>0.002770</td>\n",
              "      <td>0.000387</td>\n",
              "      <td>1.146424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>handmade_attention_time_distributed_form</th>\n",
              "      <td>0.003004</td>\n",
              "      <td>0.000743</td>\n",
              "      <td>1.213847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68366cc2-507c-4aa7-a8f8-1e2b17471791')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68366cc2-507c-4aa7-a8f8-1e2b17471791 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68366cc2-507c-4aa7-a8f8-1e2b17471791');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}